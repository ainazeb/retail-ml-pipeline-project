# Retail Data Engineering + ML + BI Project (Snowflake â€¢ FastAPI â€¢ Docker â€¢ GitHub Actions â€¢ Power BI)

End-to-end portfolio project built on the **Online Retail II** dataset (UCI).  
It demonstrates a complete workflow from data preparation â†’ ELT in Snowflake â†’ ML modeling (RFM clustering + forecasting) â†’ BI dashboards â†’ API productization â†’ Docker + CI/CD.

---

## âœ… What I Built

### 1) Data Preparation (Python)
- Loaded the Online Retail II Excel (2009â€“2010 + 2010â€“2011)
- Cleaned data (missing values, types, duplicates)
- Removed cancelled invoices (Invoice starts with "C") and negative/invalid values
- Created useful features (TotalPrice, time features)
- Exported a clean CSV for ingestion

Script:
- `scripts/prepare_data.py`

---

### 2) ELT in Snowflake (RAW â†’ STAGING â†’ MART)
**RAW**
- Stage + COPY INTO raw table

**STAGING**
- Filtered invalid rows (Quantity/Price > 0, non-null CustomerID, etc.)

**MART**
- Fact table for analytics: `FCT_DAILY_SALES`
- Customer feature table for ML/BI: `DIM_CUSTOMER_FEATURES`
- Views for Power BI and API consumption

SQL scripts:
- `sql/01_raw_stage_load.sql`
- `sql/02_staging_transform.sql`
- `sql/03_mart_views.sql`

---

### 3) Machine Learning (Notebook)
Notebook:
- `notebooks/retail_ml.ipynb`

Implemented:
- **RFM feature engineering**
- **KMeans clustering** for customer segmentation
- **Time-series forecasting** (SARIMA) for future revenue

Forecast output is loaded back into Snowflake and exposed via:
- `MART.V_REVENUE_ACTUAL_FORECAST`

---

### 4) Power BI Dashboard
Built a dashboard on Snowflake views:
- Sales overview (Total Revenue, daily/weekly trends, country split)
- Customer analytics using RFM features
- Actual vs Forecast analysis

Docs/Screenshots:
- `docs/powerbi/`

---

### 5) FastAPI + Docker + CI/CD
API:
- `app/main.py` exposes endpoints that query Snowflake views and return JSON

Docker:
- `Dockerfile` builds the API container

CI/CD:
- GitHub Actions workflows in `.github/workflows/`
- CI checks build steps
- CD builds & pushes Docker image to Docker Hub on push to `main`

---

## ğŸ§± Project Structure

retail-ml-pipeline-project/
â”‚
â”œâ”€â”€ app/ # Core application logic
â”‚ â”œâ”€â”€ main.py # Entry point
â”‚ â”œâ”€â”€ db.py # Database connections
â”‚ â”œâ”€â”€ schemas.py # Data schemas
â”‚ â”œâ”€â”€ data_raw/ # Raw data
â”‚ â”œâ”€â”€ data_processed/ # Processed datasets
â”‚ â”œâ”€â”€ data_features/ # Feature-engineered data
â”‚ â””â”€â”€ models/ # Trained ML models
â”‚
â”œâ”€â”€ notebooks/ # Exploration & experimentation
â”‚ â””â”€â”€ retail_ml.ipynb
â”‚
â”œâ”€â”€ scripts/ # Data preparation scripts
â”‚ â””â”€â”€ prepare_data.py
â”‚
â”œâ”€â”€ snowflake/ # SQL pipeline (warehouse layer)
â”‚ â”œâ”€â”€ 01_setup_raw_load.sql
â”‚ â”œâ”€â”€ 02_staging_mart_views.sql
â”‚ â””â”€â”€ 03_forecast_clusters_reporting.sql
â”‚
â”œâ”€â”€ PowerBI_dashboard/ # BI dashboards & screenshots
â”‚ â”œâ”€â”€ retail.dashboard.pbix
â”‚ â”œâ”€â”€ dashboard.png
â”‚ â”œâ”€â”€ dashboard1.png
â”‚ â”œâ”€â”€ model.png
â”‚ â””â”€â”€ README_powerbi.md
â”‚
â”œâ”€â”€ .github/workflows/ # CI/CD pipelines
â”‚ â”œâ”€â”€ ci.yml
â”‚ â””â”€â”€ cd.yml
â”‚
â”œâ”€â”€ Dockerfile # Container definition
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env # Environment variables (not committed)
â””â”€â”€ README.md # Project documentation

## ğŸ” Environment Variables

Create a `.env` file locally (DO NOT commit it):
SNOWFLAKE_ACCOUNT=...
SNOWFLAKE_USER=...
SNOWFLAKE_PASSWORD=...
SNOWFLAKE_WAREHOUSE=...
SNOWFLAKE_DATABASE=RETAIL_PROJECT
SNOWFLAKE_SCHEMA=MART
SNOWFLAKE_ROLE=...


## â–¶ï¸ Run Locally (No Docker)

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt

uvicorn app.main:app --reload
Open:

http://127.0.0.1:8000/docs

docker build -t retail-api .
docker run -d -p 8000:8000 --name retail-api --env-file .env retail-api


ğŸš€ Key Learnings

ELT patterns and layered architecture (RAW/STAGING/MART)

Building analytics-ready tables & views

RFM segmentation and customer clustering

Forecasting with SARIMA and exporting predictions

Power BI modeling + measures + slicers

Productizing analytics via FastAPI

Dockerizing services and automating CI/CD with GitHub Actions


